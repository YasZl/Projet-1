{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "eb138bda",
      "metadata": {
        "id": "eb138bda"
      },
      "source": [
        "# GREEN AI Projetct - DIA6\n",
        "# Energy Optimization in New York's Buildings Using Artificial Intelligence\n",
        "Gabriel SULTAN,\n",
        "Yasmine ZEROUAL,\n",
        "Lalith Adithya CHANUMOLU"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p data/GREENprojet/ashrae"
      ],
      "metadata": {
        "id": "87nxevfHi7J-"
      },
      "id": "87nxevfHi7J-",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls data/GREENprojet/ashrae"
      ],
      "metadata": {
        "id": "iz1m03IPi7CW",
        "outputId": "e7b787f1-9f0c-457a-b46f-507ece69aa64",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "iz1m03IPi7CW",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "building_metadata.csv\t   test.csv\t  weather_test.feather\n",
            "building_metadata.feather  test.feather   weather_train.feather\n",
            "sample_submission.csv\t   train.csv\n",
            "sample_submission.feather  train.feather\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Weather train\n",
        "df = pd.read_feather(\"data/GREENprojet/ashrae/weather_train.feather\")\n",
        "df.to_csv(\"weather_train.csv\", index=False)\n",
        "\n",
        "# Weather test\n",
        "df = pd.read_feather(\"data/GREENprojet/ashrae/weather_test.feather\")\n",
        "df.to_csv(\"weather_test.csv\", index=False)\n",
        "\n",
        "# Train\n",
        "df = pd.read_feather(\"data/GREENprojet/ashrae/train.feather\")\n",
        "df.to_csv(\"train.csv\", index=False)\n",
        "\n",
        "# Test\n",
        "df = pd.read_feather(\"data/GREENprojet/ashrae/test.feather\")\n",
        "df.to_csv(\"test.csv\", index=False)\n",
        "\n",
        "# Building metadata\n",
        "df = pd.read_feather(\"data/GREENprojet/ashrae/building_metadata.feather\")\n",
        "df.to_csv(\"building_metadata.csv\", index=False)\n",
        "\n",
        "# Sample submission\n",
        "df = pd.read_feather(\"data/GREENprojet/ashrae/sample_submission.feather\")\n",
        "df.to_csv(\"sample_submission.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "j7yANBFEmcEm"
      },
      "id": "j7yANBFEmcEm",
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "829b2c74",
      "metadata": {
        "id": "829b2c74",
        "outputId": "07d3ec01-63a2-48d4-ce2b-a6abfb81278a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 567
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '../../data/GREENprojet/ashrae/weather_train.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3865751302.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# 'infer_datetime_format' is deprecated and can be safely omitted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m weather_df = pd.read_csv(\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mweather_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../data/GREENprojet/ashrae/weather_train.csv'"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Define data types for each column to optimize memory usage\n",
        "dtypes = {\n",
        "    'site_id': 'int8',\n",
        "    'air_temperature': 'float32',\n",
        "    'cloud_coverage': 'float32',\n",
        "    'dew_temperature': 'float32',\n",
        "    'precip_depth_1_hr': 'float32',\n",
        "    'sea_level_pressure': 'float32',\n",
        "    'wind_direction': 'float32',\n",
        "    'wind_speed': 'float32'\n",
        "}\n",
        "\n",
        "weather_file = '../../data/GREENprojet/ashrae/weather_train.csv'\n",
        "parse_dates = ['timestamp']\n",
        "\n",
        "# 'infer_datetime_format' is deprecated and can be safely omitted\n",
        "weather_df = pd.read_csv(\n",
        "    weather_file,\n",
        "    dtype=dtypes,\n",
        "    parse_dates=parse_dates,\n",
        "    low_memory=True\n",
        ")\n",
        "\n",
        "weather_df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83881c76",
      "metadata": {
        "id": "83881c76"
      },
      "outputs": [],
      "source": [
        "# Charger le fichier train.csv avec optimisation de la m√©moire\n",
        "# Ce fichier contient les donn√©es de consommation √©nerg√©tique pour l'entra√Ænement\n",
        "\n",
        "# D√©finir les types de donn√©es pour optimiser la m√©moire\n",
        "train_dtypes = {\n",
        "    'building_id': 'int16',\n",
        "    'meter': 'int8',\n",
        "    'meter_reading': 'float32'\n",
        "}\n",
        "\n",
        "train_file = '../../data/GREENprojet/ashrae/train.csv'\n",
        "\n",
        "print(\"‚è≥ Chargement du fichier train.csv (cela peut prendre quelques minutes)...\")\n",
        "\n",
        "# Charger le fichier avec types optimis√©s\n",
        "train_df = pd.read_csv(\n",
        "    train_file,\n",
        "    dtype=train_dtypes,\n",
        "    parse_dates=['timestamp'],\n",
        "    low_memory=False\n",
        ")\n",
        "\n",
        "print(f\"‚úÖ Chargement termin√© !\")\n",
        "print(f\"üìä Dimensions: {train_df.shape[0]:,} lignes √ó {train_df.shape[1]} colonnes\")\n",
        "print(f\"üíæ M√©moire utilis√©e: {train_df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
        "\n",
        "train_df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4bccb0f6",
      "metadata": {
        "id": "4bccb0f6"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "# Display basic information about the weather dataset\n",
        "print(\"Weather Data Info:\")\n",
        "print(weather_df.info())\n",
        "print(\"\\nWeather Data Description:\")\n",
        "print(weather_df.describe())\n",
        "print(\"\\nWeather Data Missing Values:\")\n",
        "print(weather_df.isnull().sum())\n",
        "\n",
        "# Plotting distributions of major weather features\n",
        "features_to_plot = [\n",
        "    'air_temperature', 'dew_temperature',\n",
        "    'cloud_coverage', 'precip_depth_1_hr',\n",
        "    'sea_level_pressure', 'wind_direction', 'wind_speed'\n",
        "]\n",
        "\n",
        "plt.figure(figsize=(20, 14))\n",
        "for i, feature in enumerate(features_to_plot):\n",
        "    plt.subplot(3, 3, i+1)\n",
        "    sns.histplot(weather_df[feature].dropna(), kde=True, bins=50)\n",
        "    plt.title(f'Distribution of {feature}')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Time series trends for air_temperature\n",
        "plt.figure(figsize=(16,6))\n",
        "for site in weather_df['site_id'].unique()[:3]:  # Plotting for a few sites\n",
        "    site_df = weather_df[weather_df['site_id'] == site]\n",
        "    plt.plot(site_df['timestamp'], site_df['air_temperature'], label=f'Site {site}', alpha=0.7)\n",
        "plt.title(\"Air Temperature Trend for Sample Sites\")\n",
        "plt.xlabel(\"Timestamp\")\n",
        "plt.ylabel(\"Air Temperature (¬∞C)\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Heatmap of missing values in a random sample\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.heatmap(weather_df.sample(1000).isnull(), cbar=False, cmap='viridis')\n",
        "plt.title(\"Missing Values Heatmap (Sample of 1000 Rows)\")\n",
        "plt.show()\n",
        "\n",
        "print(\"missing values in the weather data\")\n",
        "print(weather_df.isnull().sum())\n",
        "print(\"\\nrange of air temperatures recorded\")\n",
        "print(weather_df['air_temperature'].describe())\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cdb0afe2",
      "metadata": {
        "id": "cdb0afe2"
      },
      "outputs": [],
      "source": [
        "# Exploring the distribution of the target variable: meter_reading\n",
        "\n",
        "# Check if train_df is loaded\n",
        "if 'train_df' in globals() and train_df is not None and 'meter_reading' in train_df.columns:\n",
        "    print(\"Summary Statistics for meter_reading:\")\n",
        "    print(train_df['meter_reading'].describe())\n",
        "\n",
        "    plt.figure(figsize=(12,6))\n",
        "    sns.histplot(train_df['meter_reading'], bins=100, kde=True)\n",
        "    plt.title('Distribution of Meter Reading')\n",
        "    plt.xlabel('Meter Reading')\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.show()\n",
        "\n",
        "    # Checking distribution after log(1 + x) transform (to address skewness)\n",
        "    plt.figure(figsize=(12,6))\n",
        "    sns.histplot(np.log1p(train_df['meter_reading']), bins=100, kde=True, color='orange')\n",
        "    plt.title('Distribution of log(1 + Meter Reading)')\n",
        "    plt.xlabel('log(1 + Meter Reading)')\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.show()\n",
        "\n",
        "    zero_count = (train_df['meter_reading'] == 0).sum()\n",
        "    print(f\"Number of zero meter readings: {zero_count}\")\n",
        "else:\n",
        "    print(\"train_df is not loaded or does not contain 'meter_reading' column.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0e0ebce9",
      "metadata": {
        "id": "0e0ebce9"
      },
      "source": [
        "Observations :\n",
        "\n",
        "Meter reading values are highly skewed, and it is impossible to visualize raw meter values.\n",
        "We can apply log transformation to make the distribution normal"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8c99cd77",
      "metadata": {
        "id": "8c99cd77"
      },
      "source": [
        "A right-skewed distribution can be attributed to a large number of zero or missing meter readings. It is impossible for a meter to record zero values, thereby suggesting missing meter values. We can drop off these values before training the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "090aa24c",
      "metadata": {
        "id": "090aa24c"
      },
      "outputs": [],
      "source": [
        "# Remove rows where meter_reading is zero or missing, and create a cleaned DataFrame for modeling\n",
        "if 'train_df' in globals() and train_df is not None and 'meter_reading' in train_df.columns:\n",
        "    # Drop rows with NaN meter_reading first (should be rare)\n",
        "    cleaned_train_df = train_df.dropna(subset=['meter_reading'])\n",
        "    # Then drop rows where meter_reading is exactly zero\n",
        "    cleaned_train_df = cleaned_train_df[cleaned_train_df['meter_reading'] != 0]\n",
        "    print(f\"Original training set shape: {train_df.shape}\")\n",
        "    print(f\"Shape after removing zero/missing meter_reading rows: {cleaned_train_df.shape}\")\n",
        "else:\n",
        "    print(\"train_df is not loaded or does not contain 'meter_reading' column.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a0e45829",
      "metadata": {
        "id": "a0e45829"
      },
      "outputs": [],
      "source": [
        "# Time series analysis of meter readings for different meters\n",
        "\n",
        "if 'cleaned_train_df' in globals() and cleaned_train_df is not None:\n",
        "    # Ensure 'timestamp' is datetime\n",
        "    cleaned_train_df['timestamp'] = pd.to_datetime(cleaned_train_df['timestamp'])\n",
        "\n",
        "    # Aggregate (sum) meter readings by meter type and timestamp (daily)\n",
        "    meter_types = {0: 'Electricity', 1: 'Chilled Water', 2: 'Steam', 3: 'Hot Water'}\n",
        "    cleaned_train_df['meter_label'] = cleaned_train_df['meter'].map(meter_types)\n",
        "\n",
        "    # Daily total meter readings for each meter type\n",
        "    daily_meter = (\n",
        "        cleaned_train_df\n",
        "        .groupby(['timestamp', 'meter_label'])['meter_reading']\n",
        "        .sum()\n",
        "        .reset_index()\n",
        "    )\n",
        "    # Pivot for easier plotting\n",
        "    daily_meter_pivot = daily_meter.pivot(index='timestamp', columns='meter_label', values='meter_reading')\n",
        "\n",
        "    # Plot timeseries for each meter type (total meter reading per day)\n",
        "    plt.figure(figsize=(20, 8))\n",
        "    for meter in meter_types.values():\n",
        "        if meter in daily_meter_pivot.columns:\n",
        "            plt.plot(daily_meter_pivot.index, daily_meter_pivot[meter], label=meter)\n",
        "    plt.title('Total Daily Meter Readings by Meter Type (Train Set)')\n",
        "    plt.xlabel('Date')\n",
        "    plt.ylabel('Total Meter Reading')\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Mean and total energy consumption by meter type\n",
        "    meter_stats = cleaned_train_df.groupby('meter_label')['meter_reading'].agg(['mean', 'sum']).sort_values('mean', ascending=False)\n",
        "    print(\"Mean and Total Meter Readings by Meter Type:\")\n",
        "    print(meter_stats)\n",
        "else:\n",
        "    print(\"cleaned_train_df is not loaded or not defined.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ee22889",
      "metadata": {
        "id": "5ee22889"
      },
      "outputs": [],
      "source": [
        "# Charger les m√©tadonn√©es des b√¢timents\n",
        "building_metadata_file = '../../data/GREENprojet/ashrae/building_metadata.csv'\n",
        "\n",
        "# D√©finir les types de donn√©es pour optimiser la m√©moire (√©viter float16 car pandas ne le supporte pas en lecture)\n",
        "building_dtypes = {\n",
        "    'site_id': 'int8',\n",
        "    'building_id': 'int16',\n",
        "    'square_feet': 'int32',\n",
        "    'year_built': 'float32',      # Remplacer 'float16' par 'float32'\n",
        "    'floor_count': 'float32'      # Remplacer 'float16' par 'float32'\n",
        "}\n",
        "\n",
        "print(\"‚è≥ Chargement des m√©tadonn√©es des b√¢timents...\")\n",
        "\n",
        "building_metadata_df = pd.read_csv(\n",
        "    building_metadata_file,\n",
        "    dtype=building_dtypes,\n",
        "    low_memory=False\n",
        ")\n",
        "\n",
        "print(f\"‚úÖ Chargement termin√© !\")\n",
        "print(f\"üìä Dimensions: {building_metadata_df.shape[0]:,} b√¢timents √ó {building_metadata_df.shape[1]} caract√©ristiques\")\n",
        "print(f\"üíæ M√©moire utilis√©e: {building_metadata_df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
        "\n",
        "# Afficher les premi√®res lignes\n",
        "print(\"\\nüè¢ Aper√ßu des m√©tadonn√©es des b√¢timents :\")\n",
        "display(building_metadata_df.head(10))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0db04a1",
      "metadata": {
        "id": "e0db04a1"
      },
      "outputs": [],
      "source": [
        "# Analyse exploratoire des m√©tadonn√©es des b√¢timents\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"INFORMATIONS G√âN√âRALES SUR LES B√ÇTIMENTS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(\"\\nüìä Informations sur les colonnes :\")\n",
        "print(building_metadata_df.info())\n",
        "\n",
        "print(\"\\nüìà Statistiques descriptives :\")\n",
        "print(building_metadata_df.describe())\n",
        "\n",
        "print(\"\\n‚ùì Valeurs manquantes :\")\n",
        "missing_values = building_metadata_df.isnull().sum()\n",
        "missing_percent = (missing_values / len(building_metadata_df)) * 100\n",
        "missing_df = pd.DataFrame({\n",
        "    'Valeurs manquantes': missing_values,\n",
        "    'Pourcentage (%)': missing_percent\n",
        "})\n",
        "print(missing_df[missing_df['Valeurs manquantes'] > 0])\n",
        "\n",
        "print(f\"\\nüè¢ Nombre de b√¢timents uniques : {building_metadata_df['building_id'].nunique()}\")\n",
        "print(f\"üìç Nombre de sites uniques : {building_metadata_df['site_id'].nunique()}\")\n",
        "print(f\"üèóÔ∏è Nombre d'usages primaires uniques : {building_metadata_df['primary_use'].nunique()}\")\n",
        "\n",
        "print(\"\\nüèóÔ∏è R√©partition des b√¢timents par site :\")\n",
        "print(building_metadata_df['site_id'].value_counts().sort_index())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "918b1af5",
      "metadata": {
        "id": "918b1af5"
      },
      "outputs": [],
      "source": [
        "# Visualisation des distributions des caract√©ristiques des b√¢timents\n",
        "\n",
        "fig, axes = plt.subplots(2, 3, figsize=(20, 12))\n",
        "\n",
        "# 1. Distribution de la superficie (square_feet)\n",
        "axes[0, 0].hist(building_metadata_df['square_feet'].dropna(), bins=50, color='skyblue', edgecolor='black')\n",
        "axes[0, 0].set_title('Distribution de la Superficie (square_feet)', fontsize=14, fontweight='bold')\n",
        "axes[0, 0].set_xlabel('Superficie (pieds carr√©s)')\n",
        "axes[0, 0].set_ylabel('Fr√©quence')\n",
        "axes[0, 0].ticklabel_format(style='plain', axis='x')\n",
        "\n",
        "# 2. Distribution de l'ann√©e de construction (year_built)\n",
        "axes[0, 1].hist(building_metadata_df['year_built'].dropna(), bins=50, color='lightcoral', edgecolor='black')\n",
        "axes[0, 1].set_title('Distribution de l\\'Ann√©e de Construction', fontsize=14, fontweight='bold')\n",
        "axes[0, 1].set_xlabel('Ann√©e de construction')\n",
        "axes[0, 1].set_ylabel('Fr√©quence')\n",
        "\n",
        "# 3. Distribution du nombre d'√©tages (floor_count)\n",
        "axes[0, 2].hist(building_metadata_df['floor_count'].dropna(), bins=50, color='lightgreen', edgecolor='black')\n",
        "axes[0, 2].set_title('Distribution du Nombre d\\'√âtages', fontsize=14, fontweight='bold')\n",
        "axes[0, 2].set_xlabel('Nombre d\\'√©tages')\n",
        "axes[0, 2].set_ylabel('Fr√©quence')\n",
        "\n",
        "# 4. Boxplot de la superficie\n",
        "axes[1, 0].boxplot(building_metadata_df['square_feet'].dropna(), vert=True)\n",
        "axes[1, 0].set_title('Boxplot de la Superficie', fontsize=14, fontweight='bold')\n",
        "axes[1, 0].set_ylabel('Superficie (pieds carr√©s)')\n",
        "\n",
        "# 5. Boxplot de l'ann√©e de construction\n",
        "axes[1, 1].boxplot(building_metadata_df['year_built'].dropna(), vert=True)\n",
        "axes[1, 1].set_title('Boxplot de l\\'Ann√©e de Construction', fontsize=14, fontweight='bold')\n",
        "axes[1, 1].set_ylabel('Ann√©e')\n",
        "\n",
        "# 6. Boxplot du nombre d'√©tages\n",
        "axes[1, 2].boxplot(building_metadata_df['floor_count'].dropna(), vert=True)\n",
        "axes[1, 2].set_title('Boxplot du Nombre d\\'√âtages', fontsize=14, fontweight='bold')\n",
        "axes[1, 2].set_ylabel('Nombre d\\'√©tages')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Statistiques sur les b√¢timents anciens et modernes\n",
        "print(\"\\nüèõÔ∏è ANALYSE TEMPORELLE DES B√ÇTIMENTS\")\n",
        "print(\"=\"*60)\n",
        "oldest_year = building_metadata_df['year_built'].min()\n",
        "newest_year = building_metadata_df['year_built'].max()\n",
        "print(f\"B√¢timent le plus ancien : {oldest_year}\")\n",
        "print(f\"B√¢timent le plus r√©cent : {newest_year}\")\n",
        "print(f\"√âtendue : {int(newest_year - oldest_year)} ans\")\n",
        "\n",
        "# Statistiques sur la taille des b√¢timents\n",
        "print(\"\\nüè¢ ANALYSE DE LA TAILLE DES B√ÇTIMENTS\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Superficie minimale : {building_metadata_df['square_feet'].min():,.0f} pieds carr√©s\")\n",
        "print(f\"Superficie maximale : {building_metadata_df['square_feet'].max():,.0f} pieds carr√©s\")\n",
        "print(f\"Superficie m√©diane : {building_metadata_df['square_feet'].median():,.0f} pieds carr√©s\")\n",
        "\n",
        "# Statistiques sur les √©tages\n",
        "print(\"\\nüèóÔ∏è ANALYSE DES √âTAGES\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Nombre minimal d'√©tages : {building_metadata_df['floor_count'].min():.0f}\")\n",
        "print(f\"Nombre maximal d'√©tages : {building_metadata_df['floor_count'].max():.0f}\")\n",
        "print(f\"Nombre m√©dian d'√©tages : {building_metadata_df['floor_count'].median():.0f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "13133830",
      "metadata": {
        "id": "13133830"
      },
      "source": [
        "### Usage Primaire vs. Relev√©s de Compteur\n",
        "\n",
        "Nous allons maintenant voir si la caract√©ristique `primary_use` peut √™tre s√©lectionn√©e pour pr√©dire les relev√©s de compteur.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d93f251",
      "metadata": {
        "id": "9d93f251"
      },
      "outputs": [],
      "source": [
        "# Analyse de l'usage primaire (primary_use)\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"ANALYSE DE L'USAGE PRIMAIRE DES B√ÇTIMENTS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Compter le nombre de b√¢timents par usage primaire\n",
        "primary_use_counts = building_metadata_df['primary_use'].value_counts()\n",
        "print(\"\\nüìä Nombre de b√¢timents par usage primaire :\")\n",
        "print(primary_use_counts)\n",
        "\n",
        "# Visualisation : Distribution des usages primaires\n",
        "fig, axes = plt.subplots(1, 2, figsize=(20, 6))\n",
        "\n",
        "# Graphique √† barres\n",
        "primary_use_counts.plot(kind='bar', ax=axes[0], color='teal', edgecolor='black')\n",
        "axes[0].set_title('Nombre de B√¢timents par Usage Primaire', fontsize=16, fontweight='bold')\n",
        "axes[0].set_xlabel('Usage Primaire', fontsize=12)\n",
        "axes[0].set_ylabel('Nombre de B√¢timents', fontsize=12)\n",
        "axes[0].tick_params(axis='x', rotation=45)\n",
        "axes[0].grid(axis='y', alpha=0.3)\n",
        "\n",
        "# Graphique circulaire (pie chart) pour les top 10\n",
        "top_10_uses = primary_use_counts.head(10)\n",
        "colors = plt.cm.tab20c(range(len(top_10_uses)))\n",
        "axes[1].pie(top_10_uses, labels=top_10_uses.index, autopct='%1.1f%%', startangle=90, colors=colors)\n",
        "axes[1].set_title('Top 10 des Usages Primaires (% de b√¢timents)', fontsize=16, fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\n‚úÖ Une majorit√© de b√¢timents ont un usage primaire 'Education', suivi par 'Office'.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c830f9a",
      "metadata": {
        "id": "8c830f9a"
      },
      "outputs": [],
      "source": [
        "# Fusionner les m√©tadonn√©es des b√¢timents avec les donn√©es de consommation √©nerg√©tique\n",
        "\n",
        "print(\"‚è≥ Fusion des m√©tadonn√©es des b√¢timents avec les relev√©s de compteur...\")\n",
        "\n",
        "# Fusionner cleaned_train_df avec building_metadata_df sur building_id\n",
        "merged_df = cleaned_train_df.merge(\n",
        "    building_metadata_df,\n",
        "    on='building_id',\n",
        "    how='left'\n",
        ")\n",
        "\n",
        "print(f\"‚úÖ Fusion termin√©e !\")\n",
        "print(f\"üìä Dimensions du DataFrame fusionn√© : {merged_df.shape[0]:,} lignes √ó {merged_df.shape[1]} colonnes\")\n",
        "print(f\"üíæ M√©moire utilis√©e: {merged_df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
        "\n",
        "# V√©rifier les premi√®res lignes\n",
        "print(\"\\nüîç Aper√ßu des donn√©es fusionn√©es :\")\n",
        "merged_df.head(10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3df36baf",
      "metadata": {
        "id": "3df36baf"
      },
      "outputs": [],
      "source": [
        "# Analyse de la consommation √©nerg√©tique par usage primaire\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"CONSOMMATION √âNERG√âTIQUE PAR USAGE PRIMAIRE\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Calculer les statistiques par usage primaire\n",
        "primary_use_stats = merged_df.groupby('primary_use')['meter_reading'].agg([\n",
        "    ('Nombre de relev√©s', 'count'),\n",
        "    ('Consommation moyenne', 'mean'),\n",
        "    ('Consommation totale', 'sum'),\n",
        "    ('Consommation m√©diane', 'median'),\n",
        "    ('√âcart-type', 'std')\n",
        "]).sort_values('Consommation moyenne', ascending=False)\n",
        "\n",
        "print(\"\\nüìä Statistiques de consommation √©nerg√©tique par usage primaire :\")\n",
        "print(primary_use_stats)\n",
        "\n",
        "# Visualisation : Consommation moyenne par usage primaire\n",
        "fig, axes = plt.subplots(1, 2, figsize=(22, 7))\n",
        "\n",
        "# Graphique 1 : Consommation moyenne\n",
        "primary_use_stats['Consommation moyenne'].sort_values(ascending=True).plot(\n",
        "    kind='barh',\n",
        "    ax=axes[0],\n",
        "    color='steelblue',\n",
        "    edgecolor='black'\n",
        ")\n",
        "axes[0].set_title('Consommation √ânerg√©tique Moyenne par Usage Primaire', fontsize=14, fontweight='bold')\n",
        "axes[0].set_xlabel('Consommation moyenne (kWh)', fontsize=12)\n",
        "axes[0].set_ylabel('Usage Primaire', fontsize=12)\n",
        "axes[0].grid(axis='x', alpha=0.3)\n",
        "\n",
        "# Graphique 2 : Consommation totale\n",
        "primary_use_stats['Consommation totale'].sort_values(ascending=True).plot(\n",
        "    kind='barh',\n",
        "    ax=axes[1],\n",
        "    color='coral',\n",
        "    edgecolor='black'\n",
        ")\n",
        "axes[1].set_title('Consommation √ânerg√©tique Totale par Usage Primaire', fontsize=14, fontweight='bold')\n",
        "axes[1].set_xlabel('Consommation totale (kWh)', fontsize=12)\n",
        "axes[1].set_ylabel('Usage Primaire', fontsize=12)\n",
        "axes[1].ticklabel_format(style='scientific', axis='x', scilimits=(0,0))\n",
        "axes[1].grid(axis='x', alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n‚úÖ La consommation √©nerg√©tique moyenne est principalement influenc√©e par 'Education' et 'Services'.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a8ee2a85",
      "metadata": {
        "id": "a8ee2a85"
      },
      "source": [
        "De la meme maniere nous pourrions r√©aliser une analyse en comparant^la consomation √† l'age du batiment, le nombre d'√©tage, la superficie..."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b86cc9a7",
      "metadata": {
        "id": "b86cc9a7"
      },
      "source": [
        "## Analyse de l'Impact de Site ID et Building ID sur la Consommation √ânerg√©tique\n",
        "\n",
        "Nous allons maintenant analyser si les caract√©ristiques `site_id` et `building_id` affectent la consommation √©nerg√©tique afin de **d√©tecter les valeurs aberrantes (outliers)**.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "edc7323c",
      "metadata": {
        "id": "edc7323c"
      },
      "source": [
        "### Analyse de la Consommation par Site (Site ID)\n",
        "\n",
        "Les relev√©s de compteur ont √©t√© enregistr√©s sur **16 sites diff√©rents**. Analysons les diff√©rences de consommation √©nerg√©tique entre ces sites.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c252f7ad",
      "metadata": {
        "id": "c252f7ad"
      },
      "outputs": [],
      "source": [
        "# Analyse de la consommation √©nerg√©tique par site\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"ANALYSE DE LA CONSOMMATION √âNERG√âTIQUE PAR SITE\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Calculer les statistiques par site\n",
        "site_stats = merged_df.groupby('site_id')['meter_reading'].agg([\n",
        "    ('Nombre de relev√©s', 'count'),\n",
        "    ('Consommation moyenne', 'mean'),\n",
        "    ('Consommation m√©diane', 'median'),\n",
        "    ('Consommation totale', 'sum'),\n",
        "    ('√âcart-type', 'std'),\n",
        "    ('Min', 'min'),\n",
        "    ('Max', 'max')\n",
        "]).sort_values('Consommation moyenne', ascending=False)\n",
        "\n",
        "print(\"\\nüìä Statistiques de consommation par site :\")\n",
        "print(site_stats)\n",
        "\n",
        "# Calculer le coefficient de variation (CV) pour identifier la variabilit√©\n",
        "site_stats['Coefficient de variation (%)'] = (site_stats['√âcart-type'] / site_stats['Consommation moyenne']) * 100\n",
        "\n",
        "print(\"\\nüìà Sites avec la plus forte variabilit√© (Coefficient de Variation) :\")\n",
        "print(site_stats[['Consommation moyenne', 'Coefficient de variation (%)']].sort_values('Coefficient de variation (%)', ascending=False))\n",
        "\n",
        "# Nombre de b√¢timents par site\n",
        "buildings_per_site = building_metadata_df.groupby('site_id').size().reset_index(name='Nombre de b√¢timents')\n",
        "print(\"\\nüè¢ Nombre de b√¢timents par site :\")\n",
        "print(buildings_per_site)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "212727bb",
      "metadata": {
        "id": "212727bb"
      },
      "outputs": [],
      "source": [
        "# Visualisation de la consommation par site\n",
        "\n",
        "fig, axes = plt.subplots(2, 2, figsize=(20, 14))\n",
        "\n",
        "# 1. Consommation moyenne par site\n",
        "site_stats['Consommation moyenne'].plot(\n",
        "    kind='bar',\n",
        "    ax=axes[0, 0],\n",
        "    color='steelblue',\n",
        "    edgecolor='black'\n",
        ")\n",
        "axes[0, 0].set_title('Consommation √ânerg√©tique Moyenne par Site', fontsize=14, fontweight='bold')\n",
        "axes[0, 0].set_xlabel('Site ID', fontsize=12)\n",
        "axes[0, 0].set_ylabel('Consommation Moyenne (kWh)', fontsize=12)\n",
        "axes[0, 0].grid(axis='y', alpha=0.3)\n",
        "axes[0, 0].tick_params(axis='x', rotation=0)\n",
        "\n",
        "# 2. Consommation totale par site\n",
        "site_stats['Consommation totale'].plot(\n",
        "    kind='bar',\n",
        "    ax=axes[0, 1],\n",
        "    color='coral',\n",
        "    edgecolor='black'\n",
        ")\n",
        "axes[0, 1].set_title('Consommation √ânerg√©tique Totale par Site', fontsize=14, fontweight='bold')\n",
        "axes[0, 1].set_xlabel('Site ID', fontsize=12)\n",
        "axes[0, 1].set_ylabel('Consommation Totale (kWh)', fontsize=12)\n",
        "axes[0, 1].ticklabel_format(style='scientific', axis='y', scilimits=(0,0))\n",
        "axes[0, 1].grid(axis='y', alpha=0.3)\n",
        "axes[0, 1].tick_params(axis='x', rotation=0)\n",
        "\n",
        "# 3. Boxplot de la consommation par site (√©chelle log)\n",
        "sample_sites = merged_df.sample(n=min(100000, len(merged_df)), random_state=42)\n",
        "sample_sites.boxplot(\n",
        "    column='meter_reading',\n",
        "    by='site_id',\n",
        "    ax=axes[1, 0],\n",
        "    patch_artist=True\n",
        ")\n",
        "axes[1, 0].set_title('Distribution de la Consommation par Site (√©chelle log)', fontsize=14, fontweight='bold')\n",
        "axes[1, 0].set_xlabel('Site ID', fontsize=12)\n",
        "axes[1, 0].set_ylabel('Consommation (kWh)', fontsize=12)\n",
        "axes[1, 0].set_yscale('log')\n",
        "plt.suptitle('')\n",
        "\n",
        "# 4. Coefficient de variation par site\n",
        "site_stats['Coefficient de variation (%)'].sort_values().plot(\n",
        "    kind='barh',\n",
        "    ax=axes[1, 1],\n",
        "    color='lightgreen',\n",
        "    edgecolor='black'\n",
        ")\n",
        "axes[1, 1].set_title('Variabilit√© de la Consommation par Site (Coefficient de Variation)', fontsize=14, fontweight='bold')\n",
        "axes[1, 1].set_xlabel('Coefficient de Variation (%)', fontsize=12)\n",
        "axes[1, 1].set_ylabel('Site ID', fontsize=12)\n",
        "axes[1, 1].grid(axis='x', alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4494bdba",
      "metadata": {
        "id": "4494bdba"
      },
      "source": [
        "### D√©tection des Outliers par Site\n",
        "\n",
        "Utilisons des m√©thodes statistiques pour identifier les sites avec des comportements anormaux en termes de consommation √©nerg√©tique.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fce06f90",
      "metadata": {
        "id": "fce06f90"
      },
      "outputs": [],
      "source": [
        "# D√©tection des outliers par site en utilisant la m√©thode IQR (Interquartile Range)\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"D√âTECTION DES OUTLIERS PAR SITE (M√©thode IQR)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Calculer Q1, Q3 et IQR pour la consommation moyenne par site\n",
        "Q1 = site_stats['Consommation moyenne'].quantile(0.25)\n",
        "Q3 = site_stats['Consommation moyenne'].quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "\n",
        "# D√©finir les seuils pour les outliers\n",
        "lower_bound = Q1 - 1.5 * IQR\n",
        "upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "print(f\"\\nüìä Statistiques pour la d√©tection d'outliers :\")\n",
        "print(f\"Q1 (25e percentile) : {Q1:.2f} kWh\")\n",
        "print(f\"Q3 (75e percentile) : {Q3:.2f} kWh\")\n",
        "print(f\"IQR : {IQR:.2f} kWh\")\n",
        "print(f\"Seuil inf√©rieur : {lower_bound:.2f} kWh\")\n",
        "print(f\"Seuil sup√©rieur : {upper_bound:.2f} kWh\")\n",
        "\n",
        "# Identifier les sites outliers\n",
        "site_stats['Est_Outlier'] = (site_stats['Consommation moyenne'] < lower_bound) | (site_stats['Consommation moyenne'] > upper_bound)\n",
        "outlier_sites = site_stats[site_stats['Est_Outlier']]\n",
        "\n",
        "print(f\"\\nüö® SITES OUTLIERS D√âTECT√âS : {len(outlier_sites)} site(s)\")\n",
        "if len(outlier_sites) > 0:\n",
        "    print(\"\\nüìã D√©tails des sites outliers :\")\n",
        "    print(outlier_sites[['Consommation moyenne', 'Consommation m√©diane', '√âcart-type', 'Nombre de relev√©s']])\n",
        "\n",
        "    # Classifier les outliers\n",
        "    high_outliers = outlier_sites[outlier_sites['Consommation moyenne'] > upper_bound]\n",
        "    low_outliers = outlier_sites[outlier_sites['Consommation moyenne'] < lower_bound]\n",
        "\n",
        "    if len(high_outliers) > 0:\n",
        "        print(f\"\\n‚¨ÜÔ∏è Sites avec FORTE consommation anormale : {list(high_outliers.index)}\")\n",
        "    if len(low_outliers) > 0:\n",
        "        print(f\"\\n‚¨áÔ∏è Sites avec FAIBLE consommation anormale : {list(low_outliers.index)}\")\n",
        "else:\n",
        "    print(\"Aucun site outlier d√©tect√© avec la m√©thode IQR.\")\n",
        "\n",
        "# Visualisation\n",
        "fig, ax = plt.subplots(figsize=(14, 6))\n",
        "colors = ['red' if outlier else 'steelblue' for outlier in site_stats['Est_Outlier']]\n",
        "bars = ax.bar(site_stats.index.astype(str), site_stats['Consommation moyenne'], color=colors, edgecolor='black')\n",
        "\n",
        "ax.axhline(y=upper_bound, color='red', linestyle='--', linewidth=2, label=f'Seuil sup√©rieur ({upper_bound:.0f} kWh)')\n",
        "ax.axhline(y=lower_bound, color='orange', linestyle='--', linewidth=2, label=f'Seuil inf√©rieur ({lower_bound:.0f} kWh)')\n",
        "ax.axhline(y=site_stats['Consommation moyenne'].median(), color='green', linestyle='-', linewidth=2, label=f'M√©diane ({site_stats[\"Consommation moyenne\"].median():.0f} kWh)')\n",
        "\n",
        "ax.set_title('D√©tection des Sites Outliers - Consommation Moyenne', fontsize=16, fontweight='bold')\n",
        "ax.set_xlabel('Site ID', fontsize=12)\n",
        "ax.set_ylabel('Consommation Moyenne (kWh)', fontsize=12)\n",
        "ax.legend(fontsize=11)\n",
        "ax.grid(axis='y', alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "42f39d17",
      "metadata": {
        "id": "42f39d17"
      },
      "source": [
        "### Analyse de la Consommation par B√¢timent (Building ID)\n",
        "\n",
        "Examinons maintenant les diff√©rences de consommation √©nerg√©tique entre les **1449 b√¢timents** pour identifier les b√¢timents avec des comportements √©nerg√©tiques anormaux.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a474190d",
      "metadata": {
        "id": "a474190d"
      },
      "outputs": [],
      "source": [
        "# Analyse de la consommation √©nerg√©tique par b√¢timent\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"ANALYSE DE LA CONSOMMATION √âNERG√âTIQUE PAR B√ÇTIMENT\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Calculer les statistiques par b√¢timent\n",
        "building_stats = merged_df.groupby('building_id')['meter_reading'].agg([\n",
        "    ('Nombre de relev√©s', 'count'),\n",
        "    ('Consommation moyenne', 'mean'),\n",
        "    ('Consommation m√©diane', 'median'),\n",
        "    ('Consommation totale', 'sum'),\n",
        "    ('√âcart-type', 'std'),\n",
        "    ('Min', 'min'),\n",
        "    ('Max', 'max')\n",
        "]).sort_values('Consommation moyenne', ascending=False)\n",
        "\n",
        "print(f\"\\nüìä Nombre total de b√¢timents analys√©s : {len(building_stats)}\")\n",
        "print(\"\\nüîù TOP 10 des b√¢timents avec la plus forte consommation moyenne :\")\n",
        "print(building_stats.head(10))\n",
        "\n",
        "print(\"\\nüîª TOP 10 des b√¢timents avec la plus faible consommation moyenne :\")\n",
        "print(building_stats.tail(10))\n",
        "\n",
        "# Statistiques g√©n√©rales\n",
        "print(\"\\nüìà STATISTIQUES G√âN√âRALES SUR LES B√ÇTIMENTS :\")\n",
        "print(f\"Consommation moyenne globale : {building_stats['Consommation moyenne'].mean():.2f} kWh\")\n",
        "print(f\"Consommation m√©diane globale : {building_stats['Consommation moyenne'].median():.2f} kWh\")\n",
        "print(f\"√âcart-type global : {building_stats['Consommation moyenne'].std():.2f} kWh\")\n",
        "print(f\"Consommation min : {building_stats['Consommation moyenne'].min():.2f} kWh\")\n",
        "print(f\"Consommation max : {building_stats['Consommation moyenne'].max():.2f} kWh\")\n",
        "print(f\"Ratio max/min : {building_stats['Consommation moyenne'].max() / building_stats['Consommation moyenne'].min():.2f}x\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b5e8f3a",
      "metadata": {
        "id": "3b5e8f3a"
      },
      "outputs": [],
      "source": [
        "# Visualisation de la distribution de la consommation par b√¢timent\n",
        "\n",
        "fig, axes = plt.subplots(2, 2, figsize=(20, 14))\n",
        "\n",
        "# 1. Histogramme de la consommation moyenne par b√¢timent\n",
        "axes[0, 0].hist(building_stats['Consommation moyenne'], bins=100, color='skyblue', edgecolor='black')\n",
        "axes[0, 0].set_title('Distribution de la Consommation Moyenne par B√¢timent', fontsize=14, fontweight='bold')\n",
        "axes[0, 0].set_xlabel('Consommation Moyenne (kWh)', fontsize=12)\n",
        "axes[0, 0].set_ylabel('Nombre de B√¢timents', fontsize=12)\n",
        "axes[0, 0].set_yscale('log')\n",
        "axes[0, 0].grid(axis='y', alpha=0.3)\n",
        "\n",
        "# 2. Histogramme avec √©chelle logarithmique sur x\n",
        "axes[0, 1].hist(np.log1p(building_stats['Consommation moyenne']), bins=100, color='lightcoral', edgecolor='black')\n",
        "axes[0, 1].set_title('Distribution de log(1 + Consommation Moyenne) par B√¢timent', fontsize=14, fontweight='bold')\n",
        "axes[0, 1].set_xlabel('log(1 + Consommation Moyenne)', fontsize=12)\n",
        "axes[0, 1].set_ylabel('Nombre de B√¢timents', fontsize=12)\n",
        "axes[0, 1].grid(axis='y', alpha=0.3)\n",
        "\n",
        "# 3. Top 30 b√¢timents consommant le plus\n",
        "top_30_buildings = building_stats.head(30)\n",
        "axes[1, 0].barh(range(len(top_30_buildings)), top_30_buildings['Consommation moyenne'], color='steelblue', edgecolor='black')\n",
        "axes[1, 0].set_yticks(range(len(top_30_buildings)))\n",
        "axes[1, 0].set_yticklabels([f\"B√¢t. {bid}\" for bid in top_30_buildings.index])\n",
        "axes[1, 0].set_title('TOP 30 - B√¢timents avec la Plus Forte Consommation', fontsize=14, fontweight='bold')\n",
        "axes[1, 0].set_xlabel('Consommation Moyenne (kWh)', fontsize=12)\n",
        "axes[1, 0].grid(axis='x', alpha=0.3)\n",
        "axes[1, 0].invert_yaxis()\n",
        "\n",
        "# 4. Boxplot de la consommation moyenne par b√¢timent\n",
        "axes[1, 1].boxplot(building_stats['Consommation moyenne'], vert=True)\n",
        "axes[1, 1].set_title('Boxplot de la Consommation Moyenne par B√¢timent', fontsize=14, fontweight='bold')\n",
        "axes[1, 1].set_ylabel('Consommation Moyenne (kWh)', fontsize=12)\n",
        "axes[1, 1].set_yscale('log')\n",
        "axes[1, 1].grid(axis='y', alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fad8bbed",
      "metadata": {
        "id": "fad8bbed"
      },
      "outputs": [],
      "source": [
        "# D√©tection des outliers par b√¢timent - M√©thode : Z-Score UNIQUEMENT\n",
        "\n",
        "from scipy import stats\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"D√âTECTION DES OUTLIERS PAR B√ÇTIMENT - M√âTHODE Z-SCORE\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Calculer le Z-Score pour chaque b√¢timent\n",
        "building_stats['Z_Score'] = np.abs(stats.zscore(building_stats['Consommation moyenne']))\n",
        "\n",
        "# D√©finir un seuil de Z-Score (g√©n√©ralement 3 pour les outliers extr√™mes)\n",
        "z_threshold = 3\n",
        "building_stats['Est_Outlier_ZScore'] = building_stats['Z_Score'] > z_threshold\n",
        "\n",
        "outlier_buildings_zscore = building_stats[building_stats['Est_Outlier_ZScore']]\n",
        "\n",
        "print(f\"\\nüö® B√ÇTIMENTS OUTLIERS D√âTECT√âS (Z-Score > {z_threshold}) : {len(outlier_buildings_zscore)} b√¢timent(s) ({len(outlier_buildings_zscore)/len(building_stats)*100:.1f}%)\")\n",
        "\n",
        "if len(outlier_buildings_zscore) > 0:\n",
        "    print(f\"\\nüìã TOP 15 des b√¢timents outliers (Z-Score) :\")\n",
        "    print(outlier_buildings_zscore.nlargest(15, 'Z_Score')[['Consommation moyenne', 'Z_Score', 'Nombre de relev√©s']])\n",
        "\n",
        "# Visualisation Z-Score uniquement\n",
        "fig, ax = plt.subplots(1, 1, figsize=(10, 6))\n",
        "\n",
        "# Distribution des Z-Scores\n",
        "ax.hist(building_stats['Z_Score'], bins=100, color='coral', edgecolor='black', alpha=0.7)\n",
        "ax.axvline(x=z_threshold, color='red', linestyle='--', linewidth=2, label=f'Seuil Z-Score = {z_threshold}')\n",
        "ax.set_title('Distribution des Z-Scores', fontsize=14, fontweight='bold')\n",
        "ax.set_xlabel('Z-Score (valeur absolue)', fontsize=12)\n",
        "ax.set_ylabel('Nombre de B√¢timents', fontsize=12)\n",
        "ax.legend()\n",
        "ax.grid(axis='y', alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b30bff03",
      "metadata": {
        "id": "b30bff03"
      },
      "source": [
        "## Caract√©ristiques M√©t√©orologiques vs. Relev√©s de Compteur\n",
        "\n",
        "Le dataset contient √©galement plusieurs variables m√©t√©orologiques qui sont enregistr√©es au niveau du site, affectant ainsi tous les b√¢timents des m√™mes sites.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33be1db2",
      "metadata": {
        "id": "33be1db2"
      },
      "outputs": [],
      "source": [
        "# Rappel et analyse du dataset m√©t√©orologique\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"ANALYSE DU DATASET M√âT√âOROLOGIQUE\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# V√©rifier que weather_df est bien charg√©\n",
        "if 'weather_df' not in globals():\n",
        "    print(\"‚ùå Le dataset m√©t√©orologique n'est pas charg√©. Chargement en cours...\")\n",
        "    dtypes = {\n",
        "        'site_id': 'int8',\n",
        "        'air_temperature': 'float32',\n",
        "        'cloud_coverage': 'float32',\n",
        "        'dew_temperature': 'float32',\n",
        "        'precip_depth_1_hr': 'float32',\n",
        "        'sea_level_pressure': 'float32',\n",
        "        'wind_direction': 'float32',\n",
        "        'wind_speed': 'float32'\n",
        "    }\n",
        "    weather_file = '../../data/GREENprojet/ashrae/weather_train.csv'\n",
        "    weather_df = pd.read_csv(weather_file, dtype=dtypes, parse_dates=['timestamp'], low_memory=True)\n",
        "    print(\"‚úÖ Dataset m√©t√©orologique charg√©.\")\n",
        "\n",
        "print(f\"\\nüìä Dimensions du dataset m√©t√©orologique : {weather_df.shape[0]:,} lignes √ó {weather_df.shape[1]} colonnes\")\n",
        "print(f\"üíæ M√©moire utilis√©e : {weather_df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
        "\n",
        "# Statistiques descriptives\n",
        "print(\"\\nüìà Statistiques descriptives des caract√©ristiques m√©t√©orologiques :\")\n",
        "weather_stats = weather_df.describe()\n",
        "print(weather_stats)\n",
        "\n",
        "# Valeurs manquantes\n",
        "print(\"\\n‚ùì Valeurs manquantes par variable :\")\n",
        "missing_weather = weather_df.isnull().sum()\n",
        "missing_weather_pct = (missing_weather / len(weather_df)) * 100\n",
        "missing_df_weather = pd.DataFrame({\n",
        "    'Valeurs manquantes': missing_weather,\n",
        "    'Pourcentage (%)': missing_weather_pct\n",
        "})\n",
        "print(missing_df_weather)\n",
        "\n",
        "# P√©riode temporelle\n",
        "print(f\"\\nüìÖ P√©riode temporelle :\")\n",
        "print(f\"   ‚Ä¢ Date de d√©but : {weather_df['timestamp'].min()}\")\n",
        "print(f\"   ‚Ä¢ Date de fin : {weather_df['timestamp'].max()}\")\n",
        "print(f\"   ‚Ä¢ Dur√©e : {(weather_df['timestamp'].max() - weather_df['timestamp'].min()).days} jours\")\n",
        "print(f\"   ‚Ä¢ Nombre de sites : {weather_df['site_id'].nunique()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c2fa9d6",
      "metadata": {
        "id": "9c2fa9d6"
      },
      "outputs": [],
      "source": [
        "# Visualisation des distributions des variables m√©t√©orologiques (cela a deja √©t√© fait en partie\n",
        "# plus haut dans le notebook)\n",
        "\n",
        "weather_features = [\n",
        "    'air_temperature', 'dew_temperature', 'cloud_coverage',\n",
        "    'precip_depth_1_hr', 'sea_level_pressure', 'wind_direction', 'wind_speed'\n",
        "]\n",
        "\n",
        "fig, axes = plt.subplots(3, 3, figsize=(20, 16))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for i, feature in enumerate(weather_features):\n",
        "    data = weather_df[feature].dropna()\n",
        "    axes[i].hist(data, bins=50, color='skyblue', edgecolor='black', alpha=0.7)\n",
        "    axes[i].set_title(f'Distribution de {feature}', fontsize=12, fontweight='bold')\n",
        "    axes[i].set_xlabel(feature, fontsize=10)\n",
        "    axes[i].set_ylabel('Fr√©quence', fontsize=10)\n",
        "    axes[i].grid(axis='y', alpha=0.3)\n",
        "\n",
        "    # Ajouter des statistiques sur le graphique\n",
        "    mean_val = data.mean()\n",
        "    median_val = data.median()\n",
        "    axes[i].axvline(mean_val, color='red', linestyle='--', linewidth=2, label=f'Moyenne: {mean_val:.1f}')\n",
        "    axes[i].axvline(median_val, color='green', linestyle='--', linewidth=2, label=f'M√©diane: {median_val:.1f}')\n",
        "    axes[i].legend(fontsize=8)\n",
        "\n",
        "# Supprimer les axes inutilis√©s\n",
        "for j in range(len(weather_features), len(axes)):\n",
        "    fig.delaxes(axes[j])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n‚úÖ Les 7 caract√©ristiques m√©t√©orologiques ont √©t√© visualis√©es.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9210afda",
      "metadata": {
        "id": "9210afda"
      },
      "source": [
        "# Preparing the dataset / Feature Engineering\n",
        "Reducing the memory size"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}